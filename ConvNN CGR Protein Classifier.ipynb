{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import imageio\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR = '/Users/willcheney/Code/Protein CGR/pfam_softmax_data'\n",
    "\n",
    "num_of_images = 600\n",
    "\n",
    "cat_counter = [0,0,0,0] #track number of images from each category\n",
    "\n",
    "X_data = np.empty((0, 193, 291, 3))\n",
    "Y = np.array([])\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "for img in os.listdir(DIR):\n",
    "    \n",
    "    if img == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    label = int(img[-5])\n",
    "    if cat_counter[label] >= num_of_images:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        cat_counter[label] += 1\n",
    "        Y = np.append( Y, label) #add Y-label\n",
    "        \n",
    "\n",
    "        image = np.array( imageio.imread( os.path.join(DIR, img)))\n",
    "\n",
    "        image = cv2.resize(image, (0,0), fx = 0.2, fy = 0.2)\n",
    "        image = image/255.0  # Normalize pixel values\n",
    "        image = np.delete(image, 3, axis = 2 ) # Remove image metadata\n",
    "\n",
    "        image = image.reshape((1,193,291,3))\n",
    "\n",
    "        X_data = np.append(X_data, image[:,:,:,:], axis = 0)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 193, 291, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nd5LNlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check training data is in correct format [training examples, Height, Width, Channels]\n",
    "print(X_data.shape)\n",
    "plt.imshow(X_data[0,:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('Conv Classifier', X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    assert X.shape[0] == y.shape[0], 'X data dimension 0, training examples, should equal labels dimension 0 '\n",
    "    \n",
    "    x_shuffled = np.empty(X.shape) \n",
    "    y_shuffled = np.empty(y.shape)\n",
    "    \n",
    "    \n",
    "    indices = np.arange(X.shape[0])\n",
    "    rng = np.random.default_rng()\n",
    "    rng.shuffle(indices)\n",
    "    \n",
    "    x_shuffled[:,:,:,:] = X[indices,:,:,:]\n",
    "    y_shuffled[:] = y[indices]\n",
    "    \n",
    "    \n",
    "    y_shuffled  = y_shuffled.reshape(len(y_shuffled), 1)\n",
    "    \n",
    "    return x_shuffled, y_shuffled\n",
    "\n",
    "def split_data(X, y, dev_percent, test_percent):\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0], 'X data dimension 0, training examples, should equal labels dimension 0 '\n",
    "    \n",
    "    train_dev_split_index = math.floor(X.shape[0] * (1 - (dev_percent + test_percent)))\n",
    "    X_train, X_dev = X[0:train_dev_split_index,:,:,:], X[train_dev_split_index:,:,:,:]\n",
    "    y_train, y_dev = y[0:train_dev_split_index,:], y[train_dev_split_index:,:]\n",
    "    \n",
    "    if test_percent == 0:\n",
    "        return X_train, X_dev, y_train, y_dev\n",
    "    \n",
    "    else:\n",
    "        dev_test_split_index =  math.floor(X_dev.shape[0] * (1 - test_percent/(dev_percent + test_percent)))\n",
    "        X_dev, X_test = X_dev[0: dev_test_split_index,:,:,: ], X_dev[dev_test_split_index:,:,:,:]\n",
    "        y_dev, y_test = y_dev[0: dev_test_split_index,: ], y_dev[dev_test_split_index:,:]\n",
    "\n",
    "\n",
    "        return X_train, X_dev, X_test, y_train, y_dev, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_shuffled, Y_shuffled = shuffle(X_data, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('Conv_pfam_X_2400', X_shuffled)\n",
    "np.save('Conv_pfam_Y_2400', Y_shuffled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, X_test, Y_train, Y_dev, Y_test = split_data(X_shuffled, Y_shuffled, .1, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 193, 291, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plain ConvNN\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "model = tf.keras.models.Sequential(name = 'arch2_with_dropout')\n",
    "\n",
    "model.add(tf.keras.layers.Input(shape = X_train.shape[1:], name = 'input'))\n",
    "model.add(tf.keras.layers.Conv2D(8, (8,8), activation = 'relu', padding = 'same', name = 'Conv_a1'))\n",
    "model.add(tf.keras.layers.Conv2D(16, (4,4), activation = 'relu', padding = 'valid', name = 'Conv_b1'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(4, strides = (4,4), padding = 'same', name = 'MaxPool_1'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, (2,2), activation = 'relu', name = 'Conv_c1'))\n",
    "model.add(tf.keras.layers.Conv2D(64, (2,2), activation = 'relu', name = 'Conv_d1'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.MaxPooling2D(2, strides = (2,2), padding = 'same', name = 'MaxPool_2'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu', name = 'Dense_1'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu', name = 'Dense_2'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(4, name = 'Classification'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"arch2_with_dropout\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_a1 (Conv2D)             (None, 193, 291, 8)       1544      \n",
      "_________________________________________________________________\n",
      "Conv_b1 (Conv2D)             (None, 190, 288, 16)      2064      \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling2D)     (None, 48, 72, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv_c1 (Conv2D)             (None, 47, 71, 32)        2080      \n",
      "_________________________________________________________________\n",
      "Conv_d1 (Conv2D)             (None, 46, 70, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 46, 70, 64)        0         \n",
      "_________________________________________________________________\n",
      "MaxPool_4 (MaxPooling2D)     (None, 23, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 51520)             0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 64)                3297344   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "Classification (Dense)       (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 3,315,708\n",
      "Trainable params: 3,315,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = loss, optimizer = optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/26 [==============================] - 78s 3s/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.0864 - val_accuracy: 0.9625\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 75s 3s/step - loss: 0.0448 - accuracy: 0.9805 - val_loss: 0.1362 - val_accuracy: 0.9563\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 2312s 89s/step - loss: 0.0343 - accuracy: 0.9867 - val_loss: 0.0857 - val_accuracy: 0.9688\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 4827s 186s/step - loss: 0.0377 - accuracy: 0.9852 - val_loss: 0.0655 - val_accuracy: 0.9688\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 7299s 281s/step - loss: 0.0306 - accuracy: 0.9875 - val_loss: 0.1269 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1560ce630>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data = (X_dev, Y_dev), batch_size = 50, epochs = 5, shuffle = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 309ms/step - loss: 0.6048 - accuracy: 0.8562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6048263311386108, 0.856249988079071]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_X, temp_Y = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./CGR/ConvNN_protein_CGR_classifer_arch:2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leNet = tf.keras.models.Sequential(name = 'LeNet_5')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "\n",
    "\n",
    "leNet.add(tf.keras.layers.Input(shape = X_train.shape[1:], name = 'input_layer'))\n",
    "leNet.add(tf.keras.layers.Conv2D(6, (5,5), activation = 'relu', strides = 1, name = 'Conv_a1'))\n",
    "leNet.add(tf.keras.layers.MaxPool2D((2,2), 2, name = 'Max_Pool_a1'))\n",
    "\n",
    "leNet.add(tf.keras.layers.Conv2D(16, (5,5), activation = 'relu', strides = 1, name = \"Conv_b1\"))\n",
    "leNet.add(tf.keras.layers.MaxPool2D((2,2), 2, name = 'Max_Pool_b1'))\n",
    "\n",
    "leNet.add(tf.keras.layers.Flatten())\n",
    "leNet.add(tf.keras.layers.Dense(120, activation = 'relu', name = 'Dense_1'))\n",
    "\n",
    "leNet.add(tf.keras.layers.Dense(84, activation = 'relu', name = 'Dense_2'))\n",
    "\n",
    "leNet.add(tf.keras.layers.Dense(4, name = 'Classification'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leNet.compile(loss = loss, optimizer= optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_a1 (Conv2D)             (None, 189, 287, 6)       456       \n",
      "_________________________________________________________________\n",
      "Max_Pool_a1 (MaxPooling2D)   (None, 94, 143, 6)        0         \n",
      "_________________________________________________________________\n",
      "Conv_b1 (Conv2D)             (None, 90, 139, 16)       2416      \n",
      "_________________________________________________________________\n",
      "Max_Pool_b1 (MaxPooling2D)   (None, 45, 69, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 49680)             0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 120)               5961720   \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "Classification (Dense)       (None, 4)                 340       \n",
      "=================================================================\n",
      "Total params: 5,975,096\n",
      "Trainable params: 5,975,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "leNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 45s 2s/step - loss: 7.3588e-04 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.8958\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 6.1360e-04 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.8958\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 39s 2s/step - loss: 5.4177e-04 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9000\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 40s 2s/step - loss: 4.8762e-04 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.8958\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 69s 3s/step - loss: 4.4861e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150508710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leNet.fit(X_train, Y_train, validation_data = (X_dev, Y_dev), batch_size = 100, epochs = 5, shuffle = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 172ms/step - loss: 0.6948 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.694812536239624, 0.8833333253860474]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leNet.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leNet.save_weights('./CGR/leNet5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
